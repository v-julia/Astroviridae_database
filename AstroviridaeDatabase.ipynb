{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a64e6c-37e0-4727-9c19-bf81e91d90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO, Entrez\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92abba5a-f22b-4b91-9c88-2a30b7ed5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Downloads entries from GenBank Nucleotide by given query\n",
    "Saves entries to file in GenBank format\n",
    "Input:\n",
    "    query - str - query for search in GenBank\n",
    "Output:\n",
    "    outfile - str - shortname of output file with sequences in genbank format\n",
    "'''\n",
    "def fetch_seq_from_Nucleotide(query, outfile):\n",
    "\n",
    "    Entrez.email = \"A.N.Other@example.com\"\n",
    "    # list with ids obtained by query\n",
    "    record = Entrez.read(Entrez.esearch(db=\"nucleotide\", term=query, idtype=\"acc\", RetMax=1000000))\n",
    "    id_list = record['IdList']\n",
    "    print(\"Query to GenBank Nucleotide database:\\\"{}\\\"\".format(query))\n",
    "    print(\"Number of records found: {}\".format(record[\"Count\"]))\n",
    "    print(\"{} records will be downloaded\".format(len(id_list)))\n",
    "    # output file with sequences will be saved in current working dir\n",
    "    f_name = os.path.abspath(outfile)\n",
    "\n",
    "    # output file with sequences in fasta format\n",
    "    file_out = open(f_name, 'w')\n",
    "    \n",
    "    # Saving sequences \n",
    "    \n",
    "    i = 0\n",
    "    # fetch each sequence from GenBank by its ID and writes to ouput file\n",
    "    for id in id_list:\n",
    "        i+=1\n",
    "        if i % 500 ==0:\n",
    "            print(\"Downloaded {} sequences\".format(i))\n",
    "        handle = Entrez.efetch(db=\"nucleotide\", id=id, rettype=\"genbank\", retmode=\"text\")\n",
    "        for line in handle:\n",
    "            file_out.write(line)\n",
    "        handle.close()\n",
    "    file_out.close()\n",
    "    print('Finished')\n",
    "    return(f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bb4ed5-1832-4676-8515-a9339e4e1f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_metadata_from_gb(input_file):\n",
    "    '''\n",
    "    For each entry in GenBank file retrieves the following data:\n",
    "\n",
    "    # Identifiers\n",
    "    Accession\n",
    "    GenBank title (DEFINITION)\n",
    "\n",
    "    # Classification\n",
    "    Organism name\n",
    "    Species\n",
    "    Isolate\n",
    "    Strain\n",
    "    Family\n",
    "    Lineage\n",
    "\n",
    "    #Sequence quality\n",
    "    Length\n",
    "    Strand\n",
    "\n",
    "    Num of annotated CDS\n",
    "\n",
    "    ORF1a\n",
    "    ORF1b\n",
    "    ORF2\n",
    "    coords\n",
    "    \n",
    "    #Sources\n",
    "    Country\n",
    "    Tissue/Specimen/Source\n",
    "    Collection date\n",
    "    Release date\n",
    "    Submitters\n",
    "    \n",
    "    '''\n",
    "\n",
    "    '''\n",
    "     dictionary\n",
    "     entries_data[GenBank Accession] = {}\n",
    "     entries_data[GenBank Accession].keys() = [\n",
    "                                                'Version',\n",
    "                                                'GenBank title'\n",
    "                                                'Organism name',\n",
    "                                                'Species',\n",
    "                                                'Family',\n",
    "                                                'Virus Lineage',\n",
    "                                                'Length',\n",
    "                                                'Isolate',\n",
    "                                                'Strain',\n",
    "                                                'Strand',\n",
    "                                                'Geo location'\n",
    "                                                'Country',\n",
    "                                                'Tissue/Specimen/Source',\n",
    "                                                'Host',\n",
    "                                                'Collection date',\n",
    "                                                'Release date',\n",
    "                                                'Submitters',\n",
    "                                                'Sequencing Technology'\n",
    "                                                'CDS number'\n",
    "                                                ]\n",
    "    '''\n",
    "    entries_data = {}\n",
    "\n",
    "    source_qualifiers = [\"strain\", \"isolate\", \"geo_loc_name\", \"country\", \"collection_date\", \"isolation_source\", \"host\"]\n",
    "    source_qualifiers_columns = [\"Strain\", \"Isolate\", \"Geo location\", \"Country\", \"Collection date\", \"Tissue/Specimen/Source\", \"Host\"]\n",
    "\n",
    "    entries = SeqIO.parse(os.path.abspath(input_file), \"genbank\")\n",
    "\n",
    "    for entry in entries:\n",
    "        entries_data[entry.name] = {}\n",
    "        entries_data[entry.name]['Version'] = entry.id\n",
    "        entries_data[entry.name]['GenBank title'] = entry.description\n",
    "\n",
    "        entries_data[entry.name]['Release date'] = entry.annotations['date']\n",
    "        entries_data[entry.name]['Organism name'] = entry.annotations['organism']\n",
    "        \n",
    "        entries_data[entry.name]['Virus Lineage'] = ';'.join(entry.annotations['taxonomy'])\n",
    "        num_taxa = len(entry.annotations['taxonomy'])\n",
    "        if num_taxa == 9:\n",
    "            entries_data[entry.name]['Species'] = entry.annotations['taxonomy'][-1]\n",
    "        else:\n",
    "             entries_data[entry.name]['Species'] = 'NA'\n",
    "        entries_data[entry.name]['Family'] = entry.annotations['taxonomy'][6]\n",
    "        \n",
    "        entries_data[entry.name]['Length'] = len(entry)\n",
    "\n",
    "        for reference in entry.annotations['references']:\n",
    "            if reference.title == 'Direct Submission':\n",
    "                entries_data[entry.name]['Submitters'] = reference.authors\n",
    "\n",
    "        count_cds = 0\n",
    "        for feature in entry.features:\n",
    "            if feature.type == 'source':\n",
    "                for qualif, colname in zip(source_qualifiers, source_qualifiers_columns):\n",
    "                    if qualif in feature.qualifiers:\n",
    "                        entries_data[entry.name][colname] = feature.qualifiers[qualif][0]\n",
    "                    else:\n",
    "                        entries_data[entry.name][colname] = 'NA'\n",
    "                if 'environmental_sample' in feature.qualifiers:\n",
    "                    entries_data[entry.name]['Environmental'] = 'Yes'\n",
    "                else:\n",
    "                    entries_data[entry.name]['Environmental'] = 'No'\n",
    "                    \n",
    "            if feature.type == 'CDS':\n",
    "                \n",
    "                count_cds +=1\n",
    "                \n",
    "        entries_data[entry.name]['CDS count'] = count_cds\n",
    "\n",
    "    meta_dataframe = pd.DataFrame.from_dict(entries_data, orient='index')\n",
    "    \n",
    "    meta_dataframe.to_csv(os.path.splitext(os.path.abspath(input_file))[0] + '.csv')\n",
    "    #country_map - file with abbreviations of countries\n",
    "    return meta_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cfd169-5ef8-4943-9047-98f218a3b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_feature(feature, feature_map):\n",
    "    '''\n",
    "    feature_map - dictionary, e.g. feature_map['Italia']='ITA'\n",
    "    feature - possible key from feature_map\n",
    "    return value if key is in feature_map\n",
    "    '''\n",
    "    for k, v in feature_map.items():\n",
    "        if feature.lower() == k.lower():\n",
    "            return v\n",
    "    return feature\n",
    "\n",
    "\n",
    "def orf_coord(input_file, orf_map):\n",
    "    '''\n",
    "    Retrieves the coordinates of ORFs\n",
    "    \n",
    "    Input:\n",
    "        input_file - file with nucleotide sequences in genbank-format\n",
    "        orf_map - csv file annotation of orfs and their codes\n",
    "    Output:\n",
    "        coord_file - file with coordinates\n",
    "    '''\n",
    "\n",
    "    # dictionary with possiple names of astrovirus ORFs indicated in note, gene and product qualifiers\n",
    "    # orf_dict[\"ORF1a\"] = \"1A\"\n",
    "    orf_dict = read_csv(orf_map)\n",
    "\n",
    "    # ORFs which coordinates this script will extract\n",
    "    orf_types_final = ['1A', '1B', '2']\n",
    "    # ORFs that can be met\n",
    "    orf_types = ['1A', '1B', '1AB', '2']\n",
    "\n",
    "    # name of output file with ORF coordinates\n",
    "    out_file_name = os.path.splitext(os.path.abspath(input_file))[0] + '_orf-coords.csv'\n",
    "    print(out_file_name)\n",
    "\n",
    "\n",
    "    # dictionaruy with ORF coordinates\n",
    "    dict_coord = {}\n",
    "\n",
    "    with open(input_file) as handle:\n",
    "        records = list(SeqIO.parse(handle, 'gb'))\n",
    "\n",
    "        # entries with no annotations\n",
    "        no_annot = 0\n",
    "        # entries with no annotations of target CDS\n",
    "        no_annot_target = 0\n",
    "        # CDS with no annotations of target ORFs\n",
    "        notarget_annot_CDS = 0\n",
    "        # CDS with no annotations\n",
    "        no_annot_CDS = 0\n",
    "        for rec in records:\n",
    "\n",
    "            dict_coord[rec.name] = {}\n",
    "            # iterate over record features\n",
    "\n",
    "            # number of CDS\n",
    "            cds_count = 0\n",
    "            # number of annotated CDS with target ORFs\n",
    "            cds_annot_count = 0\n",
    "            for feature in rec.features:\n",
    "                \n",
    "                if feature.type == 'CDS':\n",
    "                    cds_count += 1\n",
    "                    \n",
    "                    # Check codon start\n",
    "                    if 'codon_start' in feature.qualifiers.keys():\n",
    "                        cod_start = int(feature.qualifiers['codon_start'][0]) - 1\n",
    "                        if cod_start<0:\n",
    "                            print('Codon start < 0, something is wrong')\n",
    "                    else:\n",
    "                        cod_start = 0\n",
    "\n",
    "                    # check all annotations in gene, product, note qualifiers\n",
    "                    CDS_raw_annotations = []\n",
    "                    for el in ('product', 'gene', 'note'):\n",
    "                        CDS_raw_annotations.extend(feature.qualifiers.get(el, []))\n",
    "                    \n",
    "                    if len(CDS_raw_annotations) != 0:\n",
    "                        # now we will leave annotations of target ORFs\n",
    "                        CDS_annotations = list(map(lambda x: map_feature(x, orf_dict), CDS_raw_annotations))\n",
    "                        CDS_annotations = list(filter(lambda x: x in orf_types, CDS_annotations))\n",
    "                        if len(CDS_annotations) == 0:\n",
    "                            print(\"No annotations of target ORFs of CDS in {}\".format(rec.name))\n",
    "                            print(CDS_raw_annotations)\n",
    "                            print(rec.description)\n",
    "                            notarget_annot_CDS +=1\n",
    "                        else:\n",
    "                            #print(\"Annotations were successfully found\")\n",
    "                            #print(CDS_annotations)\n",
    "\n",
    "                            # check for consistency of CDS annotations\n",
    "                            uniq_annotations = list(set(CDS_annotations))\n",
    "                            if len(uniq_annotations) == 1:\n",
    "                                CDS_product = uniq_annotations[0]\n",
    "                                # CDS is a target ORF, the coordinates are not joined\n",
    "                                if CDS_product in orf_types_final:\n",
    "                                    dict_coord[rec.name][CDS_product] = [int(feature.location.start) + cod_start, int(feature.location.end)]\n",
    "                                    dict_coord[rec.name][CDS_product + '-chain'] = feature.location.strand\n",
    "                                    cds_annot_count +=1\n",
    "                                elif CDS_product == \"1AB\":\n",
    "\n",
    "                                    # check whether the coordinates are joined\n",
    "                                    if len(feature.location.parts) == 2:\n",
    "                                        dict_coord[rec.name]['1A'] = [int(feature.location.parts[0].start) + cod_start, int(feature.location.parts[0].end)]\n",
    "                                        dict_coord[rec.name]['1A-chain'] = feature.location.parts[0].strand\n",
    "                                        dict_coord[rec.name]['1B'] = [int(feature.location.parts[1].start), int(feature.location.parts[1].end)]\n",
    "                                        dict_coord[rec.name]['1B-chain'] = feature.location.parts[1].strand\n",
    "                                        cds_annot_count +=1\n",
    "                                    elif len(feature.location.parts) == 1:\n",
    "                                        dict_coord[rec.name]['1B'] = [int(feature.location.parts[0].start) + cod_start, int(feature.location.parts[0].end)]\n",
    "                                        dict_coord[rec.name]['1B-chain'] = feature.location.parts[0].strand\n",
    "                                        cds_annot_count +=1\n",
    "                                    else:\n",
    "                                        print(\"strange locations in {}\".format(rec.name))\n",
    "                                        print(feature.location)\n",
    "                            else:\n",
    "                                print(\"Conflicting CDS annotations for {}\".format(rec.name))\n",
    "                    \n",
    "                                    \n",
    "                        \n",
    "                    else:\n",
    "                        print(\"No annotations of CDS in {}\".format(rec.name))\n",
    "                        print(rec.description)\n",
    "                        print(feature)\n",
    "                        no_annot_CDS +=1\n",
    "            \n",
    "            if cds_count == 0:\n",
    "                print(\"{} has no CDS in annotation\".format(rec.name))\n",
    "                print(rec.description)\n",
    "                no_annot +=1\n",
    "            if cds_annot_count == 0:\n",
    "                print(\"{} has no CDS of target ORFs\".format(rec.name))\n",
    "                no_annot_target +=1\n",
    "                print(rec.description)\n",
    "\n",
    "\n",
    "\n",
    "        # Write extracted coordinates to file\n",
    "        with open(out_file_name, 'w') as out_file:\n",
    "            line = \"GBAC\"\n",
    "            for ORF in orf_types_final:\n",
    "                line = line + ',' + ORF + ',' + ORF + '-chain'\n",
    "            out_file.write(line + '\\n')\n",
    "            for rec_id, values in dict_coord.items():\n",
    "                s = rec_id\n",
    "                for orf in orf_types_final:\n",
    "                    if orf in values:\n",
    "                        s += f\",{values[orf][0]}-{values[orf][1]},{values[orf+'-chain']}\"\n",
    "                    else:\n",
    "                        s += \",NA-NA,NA\"\n",
    "                s += \"\\n\"\n",
    "                out_file.write(s)\n",
    "        out_file.close()\n",
    "\n",
    "\n",
    "        print(\"Entries with no CDS annotation: {}\".format(no_annot))\n",
    "        print(\"Entries with no CDS with target ORF annotation: {}\".format(no_annot_target))\n",
    "        print(\"CDS with no target ORFs: {}\".format(notarget_annot_CDS))\n",
    "        print(\"CDS with no annotations: {}\".format(no_annot_CDS))\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bf1e178-edbb-46b3-99db-0a4d954003ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query to GenBank Nucleotide database:\"\"txid39733\"[Organism]\"\n",
      "Number of records found: 16012\n",
      "16012 records will be downloaded\n",
      "Downloaded 500 sequences\n",
      "Downloaded 1000 sequences\n",
      "Downloaded 1500 sequences\n",
      "Downloaded 2000 sequences\n",
      "Downloaded 2500 sequences\n",
      "Downloaded 3000 sequences\n",
      "Downloaded 3500 sequences\n",
      "Downloaded 4000 sequences\n",
      "Downloaded 4500 sequences\n",
      "Downloaded 5000 sequences\n",
      "Downloaded 5500 sequences\n",
      "Downloaded 6000 sequences\n",
      "Downloaded 6500 sequences\n",
      "Downloaded 7000 sequences\n",
      "Downloaded 7500 sequences\n",
      "Downloaded 8000 sequences\n",
      "Downloaded 8500 sequences\n",
      "Downloaded 9000 sequences\n",
      "Downloaded 9500 sequences\n",
      "Downloaded 10000 sequences\n",
      "Downloaded 10500 sequences\n",
      "Downloaded 11000 sequences\n",
      "Downloaded 11500 sequences\n",
      "Downloaded 12000 sequences\n",
      "Downloaded 12500 sequences\n",
      "Downloaded 13000 sequences\n",
      "Downloaded 13500 sequences\n",
      "Downloaded 14000 sequences\n",
      "Downloaded 14500 sequences\n",
      "Downloaded 15000 sequences\n",
      "Downloaded 15500 sequences\n",
      "Downloaded 16000 sequences\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "file_gb = fetch_seq_from_Nucleotide('\"txid39733\"[Organism]' , \"Astroviridae_15102025.gb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8272523-aba2-49da-a300-12cb03eacb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"Astroviridae_15102025.gb\"\n",
    "data = fetch_metadata_from_gb(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eab5ed-d961-4ca6-843e-11e872ef368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orf_coord(\"Astroviridae_15102025_template.gb\", \"ORF_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd2e5809-d4be-4196-ad07-6aca075cf232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Virology\\RNA_viruses\\Astroviridae_database\\Astroviridae.gb\n"
     ]
    }
   ],
   "source": [
    "outfile = \"Astroviridae_15102025.gb\"\n",
    "outfile = \"D:\\Virology\\RNA_viruses\\Astroviridae_database\\Astroviridae.gb\"\n",
    "print(os.path.abspath(outfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1697f50b-2d3f-410d-a8cc-2705b51fd661",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"Astroviridae_15102025_template.gb\"\n",
    "data = fetch_metadata_from_gb(input_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
